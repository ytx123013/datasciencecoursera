for(i in 1:10){print i}
for(i in 1:10){print (i)}
ï¼Ÿseq
?seq
?seq_len
add_2 <- function(x, y){
sum = x + y
return(sum)
}
add_2(1,2)
sum <- add_2(3,4)
sum
x[above_num]
above <- function(x, n) {
above_num <- x>n
x[above_num]
}
x <- 1:50
above(x, 10)
x
x>10
x[0,0,1,1]
?mean
mean_of_col <- function(y) {
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc) {
means[i] <- mean(y[,i])
}
}
mean_of_col <- function(y, remove_NA = TRUE) {
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc) {
means[i] <- mean(y[,i], na.rm = remove_NA)
}
}
search()
?optm
?optim
?nlm
?optim
x <- as.Date("1970-01-01")
x
unclass(x)
x <- as.Date("1980-01-01")
x
unclass(x)
posixct
y <- Sys.time()
y
as.POSIXct(y)
p <- as.POSIXct(y)
p
unclass(p)
names(unclass(p))
p <- as.POSIXlt(y)
p
unclass(p)
names(unclass(p))
p$min
p
p$mday
p
x <- strptime(p, "%B %d")
x
x <- strptime(y, "%B %d")
x
y
x <- strptime(Sys.time(), "%B %d")
x
x <- Sys.time()
x
dataStr <- strptime(x, "%H:%H")
dataStr
dataStr <- strptime(x, "%B %d, %Y %H:%H")
dataStr
?strptime()
dataStr <- strptime(c(x), "%B %d, %Y %H:%H")
dataStr
x <- as.Data("2015-01-01")
x <- as.Date("2015-01-01")
y <- as.Date("2014-01-01")
x-y
getwd()
x <- 'aa'
y <- 'hehe' + x
y <- 'hehe'  x
y <- 'hehe' , x
paste('hhe',x)
?paste
paste('hehe',x,sep = '')
x <- 20
x%10
directory <- '/User'
file_id <- 2
paste(directory,'/00',file_id,sep = '')
paste(directory,'/00',file_id,'.csv',sep = '')
file_id<-10
paste(directory,'/00',file_id,'.csv',sep = '')
paste(directory,'/0',file_id,'.csv',sep = '')
file_id<-100
paste(directory,'/',file_id,'.csv',sep = '')
file_id<-99
get_file_path <- function(directory, file_id) {
if (file_id < 10){
return(paste(directory,'/00',file_id,'.csv',sep = ''))
}else if(file_id < 100 && file_id >=10){
return(paste(directory,'/0',file_id,'.csv',sep = ''))
}else{
return(paste(directory,'/',file_id,'.csv',sep = ''))
}
}
get_file_path('aaa',10)
get_file_path('aaa',9)
get_file_path('aaa',99)
get_file_path('aaa',199)
get_file_path <- function(directory, file_id) {
if (file_id < 10){
return(paste(directory,'/00',file_id,'.csv',sep = ''))
}else if(file_id < 100 && file_id >=10){
return(paste(directory,'/0',file_id,'.csv',sep = ''))
}else{
return(paste(directory,'/',file_id,'.csv',sep = ''))
}
}
pollutantmean <- function(directory ,pollutant ,id = 1:332){
for (file_id in id) {
file_path = get_file_path(directory,file_id)
data <- read.csv(file_path)
}
}
file_path = get_file_path('/Users/macmini1/github/datasciencecoursera/R programming/specdata',4)
file_path
data <- read.csv(file_path)
data
is.na(data$sulfate)
?mean
mean(data$sulfate, na.rm =  TRUE)
hehe <- numeric()
class(hehe)
hehe <- vector('numeric')
class(hehe)
?vector
rep(1, 4)
v <- c(1:5)
ind <- c('a','a','a','b','b')
tapply(v,ind)
x <- c(rnorm(10), runif(10), rnorm(10,1))
x
f <- gl(3,10)
f
tapply(x,f,mean)
?tapply
tapply(v,ind,sum)
x
f
split(x,f)
?colMeans
library("xlsx")
library("xlsx")
library("xlsx")
downURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
setwd('/Users/macmini1/github/datasciencecoursera/Get & Cleaning Data/')
download.file(downURL,'222.xml','curl')
library('XML')
readHTMLTable('222.xml')
data <- readHTMLList('222.xml')
data
xmlTreeParse(downURL,useInternalNodes = YES)
xmlTreeParse('222.xml',useInternalNodes = YES)
xmlTreeParse('222.xml',useInternalNodes = TRUE)
data <- xmlTreeParse('222.xml',useInternalNodes = TRUE)
data
xmlRoot(data)
xmlName(xmlRoot('222.xml'))
xmlName(xmlRoot(data))
rootNode <- xmlRoot(data)
rootNode
names(rootNode)
rootNode[1]
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[2]]
install.packages("xpath")
xpathSApply(rootNode,'//row',xmlValue)
node['row']
xpathSApply(rootNode,'//zipcode',xmlValue)
xpathSApply(rootNode,'//row[@class='zipcode'],xmlValue)
